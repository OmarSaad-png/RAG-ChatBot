:10.1109/FUZZY.1994.343737.ISBN0-7803-1896-X.S2CID56694947.^Vincze, David (2017)."Fuzzy rule interpolation and reinforcement learning"(PDF).2017 IEEE 15th International Symposium on Applied Machine Intelligence and Informatics (SAMI). IEEE. pp. 173178.doi:10.1109/SAMI.2017.7880298.ISBN978-1-5090-5655-2.S2CID17590120.^Ng, A. Y.; Russell, S. J. (2000)."Algorithms for Inverse Reinforcement Learning"(PDF).Proceeding ICML '00 Proceedings of the Seventeenth International Conference on Machine Learning. pp. 663670.ISBN1-55860-707-2.^Ziebart, Brian D.; Maas, Andrew; Bagnell, J. Andrew; Dey, Anind K. (2008-07-13)."Maximum entropy inverse reinforcement learning".Proceedings of the 23rd National Conference on Artificial Intelligence - Volume 3. AAAI'08. Chicago, Illinois: AAAI Press: 14331438.ISBN978-1-57735-368-3.S2CID336219.^Pitombeira-Neto, Anselmo R.; Santos, Helano P.; Coelho da Silva, Ticiana L.; de Macedo, Jos Antonio F. (March 2024)."Trajectory modeling via random utility inverse reinforcement learning".Information Sciences.660: 120128.arXiv:2105.12092.doi:10.1016/j.ins.2024.120128.ISSN0020-0255.S2CID235187141.^Garca, Javier; Fernndez, Fernando (1 January 2015)."A comprehensive survey on safe reinforcement learning"(PDF).The Journal of Machine Learning Research.16(1): 14371480.^Dabney, Will; Ostrovski, Georg; Silver, David; Munos, Remi (2018-07-03)."Implicit Quantile Networks for Distributional Reinforcement Learning".Proceedings of the 35th International Conference on Machine Learning. PMLR: 10961105.arXiv:1806.06923.^Chow, Yinlam; Tamar, Aviv; Mannor, Shie; Pavone, Marco (2015)."Risk-Sensitive and Robust Decision-Making: a CVaR Optimization Approach".Advances in Neural Information Processing Systems.28. Curran Associates, Inc.arXiv:1506.02188.^"Train Hard, Fight Easy: Robust Meta Reinforcement Learning".scholar.google.com. Retrieved2024-06-21.^Tamar, Aviv; Glassner, Yonatan; Mannor, Shie (2015-02-21)."Optimizing the CVaR via Sampling".Proceedings of the AAAI Conference on Artificial Intelligence.29(1).arXiv:1404.3862.doi:10.1609/aaai.v29i1.9561.ISSN2374-3468.^Greenberg, Ido; Chow, Yinlam; Ghavamzadeh, Mohammad; Mannor, Shie (2022-12-06)."Efficient Risk-Averse Reinforcement Learning".Advances in Neural Information Processing Systems.35: 3263932652.arXiv:2205.05138.^Bozinovski, S. (1982). "A self-learning system using secondary reinforcement". In Trappl, Robert (ed.). Cybernetics and Systems Research: Proceedings of the Sixth European Meeting on Cybernetics and Systems Research. North-Holland. pp. 397402. ISBN 978-0-444-86488-8^Bozinovski S. (1995) "Neuro genetic agents and structural theory of self-reinforcement learning systems". CMPSCI Technical Report 95-107, University of Massachusetts at Amherst[1]^Bozinovski, S. (2014) "Modeling mechanisms of cognition-emotion interaction in artificial neural networks, since 1981." Procedia Computer Science p. 255-263^Engstrom, Logan; Ilyas, Andrew; Santurkar, Shibani; Tsipras, Dimitris; Janoos, Firdaus; Rudolph, Larry; Madry, Aleksander (2019-09-25)."Implementation Matters in Deep RL: A Case Study on PPO and TRPO".ICLR.^Colas, Cdric (2019-03-06)."A Hitchhiker's Guide to Statistical Comparisons of Reinforcement Learning Algorithms".International Conference on Learning Representations.arXiv:1904.06979.^Greenberg, Ido; Mannor, Shie (2021-07-01)."Detecting Rewards Deterioration in Episodic Reinforcement Learning".Proceedings of the 38th International Conference on Machine Learning. PMLR: 38423853.arXiv:2010.11660.Further reading[edit]Annaswamy, Anuradha M. (3 May 2023)."Adaptive Control and Intersections with Reinforcement Learning".Annual Review of Control, Robotics, and Autonomous Systems.6(1): 6593.doi:10.1146/annurev-control-062922-090153.ISSN2573-5144.S2CID255702873.Auer, Peter; Jaksch, Thomas; Ortner, Ronald (2010)."Near-optimal regret bounds for reinforcement learning".Journal of Machine Learning Research.11: 15631600.Bertsekas, Dimitri P. (2023) [2019].REINFORCEMENT LEARNING AND OPTIMAL CONTROL(1st ed.). Athena Scientific.ISBN978-1-886-52939-7.Busoniu, Lucian; Babuska, Robert;De Schutter, Bart; Ernst, Damien (2010).Reinforcement Learning and Dynamic Programming using Function Approximators. Taylor & Francis CRC Press.ISBN978-1-4398-2108-4.Franois-Lavet, Vincent; Henderson, Peter; Islam, Riashat; Bellemare, Marc G.; Pineau, Joelle (2018). "An Introduction to Deep Reinforcement Learning".Foundations and Trends in Machine Learning.11(34): 219354.arXiv:1811.12560.Bibcode:2018arXiv181112560F.doi:10.1561/2200000071.S2CID54434537.Li, Shengbo Eben (2023).Reinforcement Learning for Sequential Decision and Optimal Control(1st ed.). Springer Verlag, Singapore.doi:10.1007/978-981-19-7784-8.ISBN978-9-811-97783-1.Powell, Warren (2011).Approximate dynamic programming: solving the curses of dimensionality. Wiley-Interscience. Archived fromthe originalon 2016-07-31. Retrieved2010-09-08.Sutton, Richard S.(1988)."Learning to predict by the method of temporal differences".Machine Lear