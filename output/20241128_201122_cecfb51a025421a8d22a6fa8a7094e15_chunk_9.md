weg, Han (2022)."Community energy storage operation via reinforcement learning with eligibility traces".Electric Power Systems Research.212.Bibcode:2022EPSR..21208515S.doi:10.1016/j.epsr.2022.108515.S2CID250635151.^Xie, Zhaoming; Hung Yu Ling; Nam Hee Kim; Michiel van de Panne (2020). "ALLSTEPS: Curriculum-driven Learning of Stepping Stone Skills".arXiv:2005.04323[cs.GR].^Vergara, Pedro P.; Salazar, Mauricio; Giraldo, Juan S.; Palensky, Peter (2022)."Optimal dispatch of PV inverters in unbalanced distribution systems using Reinforcement Learning".International Journal of Electrical Power & Energy Systems.136.Bibcode:2022IJEPE.13607628V.doi:10.1016/j.ijepes.2021.107628.S2CID244099841.^Sutton & Barto 2018, Chapter 11.^Ren, Yangang; Jiang, Jianhua; Zhan, Guojian; Li, Shengbo Eben; Chen, Chen; Li, Keqiang; Duan, Jingliang (2022)."Self-Learned Intelligence for Integrated Decision and Control of Automated Vehicles at Signalized Intersections".IEEE Transactions on Intelligent Transportation Systems.23(12): 2414524156.arXiv:2110.12359.doi:10.1109/TITS.2022.3196167.^Gosavi, Abhijit(2003).Simulation-based Optimization: Parametric Optimization Techniques and Reinforcement. Operations Research/Computer Science Interfaces Series. Springer.ISBN978-1-4020-7454-7.^abBurnetas, Apostolos N.;Katehakis, Michael N.(1997), "Optimal adaptive policies for Markov Decision Processes",Mathematics of Operations Research,22(1): 222255,doi:10.1287/moor.22.1.222,JSTOR3690147^Tokic, Michel; Palm, Gnther (2011),"Value-Difference Based Exploration: Adaptive Control Between Epsilon-Greedy and Softmax"(PDF),KI 2011: Advances in Artificial Intelligence, Lecture Notes in Computer Science, vol. 7006, Springer, pp. 335346,ISBN978-3-642-24455-1^abc"Reinforcement learning: An introduction"(PDF). Archived fromthe original(PDF)on 2017-07-12. Retrieved2017-07-23.^Singh, Satinder P.; Sutton, Richard S. (1996-03-01)."Reinforcement learning with replacing eligibility traces".Machine Learning.22(1): 123158.doi:10.1007/BF00114726.ISSN1573-0565.^Sutton, Richard S.(1984).Temporal Credit Assignment in Reinforcement Learning(PhD thesis). University of Massachusetts, Amherst, MA. Archived fromthe originalon 2017-03-30. Retrieved2017-03-29.^Sutton & Barto 2018,6. Temporal-Difference Learning.^Bradtke, Steven J.;Barto, Andrew G.(1996). "Learning to predict by the method of temporal differences".Machine Learning.22: 3357.CiteSeerX10.1.1.143.857.doi:10.1023/A:1018056104778.S2CID20327856.^Watkins, Christopher J.C.H.(1989).Learning from Delayed Rewards(PDF)(PhD thesis). Kings College, Cambridge, UK.^Matzliach, Barouch; Ben-Gal, Irad; Kagan, Evgeny (2022)."Detection of Static and Mobile Targets by an Autonomous Agent with Deep Q-Learning Abilities".Entropy.24(8): 1168.Bibcode:2022Entrp..24.1168M.doi:10.3390/e24081168.PMC9407070.PMID36010832.^Williams, Ronald J.(1987). "A class of gradient-estimating algorithms for reinforcement learning in neural networks".Proceedings of the IEEE First International Conference on Neural Networks.CiteSeerX10.1.1.129.8871.^Peters, Jan;Vijayakumar, Sethu;Schaal, Stefan(2003).Reinforcement Learning for Humanoid Robotics(PDF). IEEE-RAS International Conference on Humanoid Robots. Archived fromthe original(PDF)on 2013-05-12.^Juliani, Arthur (2016-12-17)."Simple Reinforcement Learning with Tensorflow Part 8: Asynchronous Actor-Critic Agents (A3C)".Medium. Retrieved2018-02-22.^Deisenroth, Marc Peter;Neumann, Gerhard;Peters, Jan(2013).A Survey on Policy Search for Robotics(PDF). Foundations and Trends in Robotics. Vol. 2. NOW Publishers. pp. 1142.doi:10.1561/2300000021.hdl:10044/1/12051.^Sutton, Richard (1990). "Integrated Architectures for Learning, Planning and Reacting based on Dynamic Programming".Machine Learning: Proceedings of the Seventh International Workshop.^Lin, Long-Ji (1992)."Self-improving reactive agents based on reinforcement learning, planning and teaching"(PDF).Machine Learning volume 8.doi:10.1007/BF00992699.^Zou, Lan (2023-01-01), Zou, Lan (ed.),"Chapter 7 - Meta-reinforcement learning",Meta-Learning, Academic Press, pp. 267297,doi:10.1016/b978-0-323-89931-4.00011-0,ISBN978-0-323-89931-4, retrieved2023-11-08^van Hasselt, Hado; Hessel, Matteo; Aslanides, John (2019)."When to use parametric models in reinforcement learning?"(PDF).Advances in Neural Information Processing Systems 32.^Grondman, Ivo; Vaandrager, Maarten; Busoniu, Lucian; Babuska, Robert; Schuitema, Erik (2012-06-01)."Efficient Model Learning Methods for ActorCritic Control".IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics).42(3): 591602.doi:10.1109/TSMCB.2011.2170565.ISSN1083-4419.PMID22156998.^"On the Use of Reinforcement Learning for Testing Game Mechanics : ACM - Computers in Entertainment".cie.acm.org. Retrieved2018-11-27.^Riveret, Regis; Gao, Yang (2019). "A probabilistic argumentation framework for reinforcement learning agents".Autonomous Agents and Multi-Agent Systems.33(12): 216274.doi:10.1007/s10458-019-09404-2.S2CID71147890.^Ya