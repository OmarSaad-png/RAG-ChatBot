Michael N.(1997), "Optimal adaptive policies for Markov Decision Processes",Mathematics of Operations Research,22(1): 222255,doi:10.1287/moor.22.1.222,JSTOR3690147^Tokic, Michel; Palm, Gnther (2011),"Value-Difference Based Exploration: Adaptive Control Between Epsilon-Greedy and Softmax"(PDF),KI 2011: Advances in Artificial Intelligence, Lecture Notes in Computer Science, vol. 7006, Springer, pp. 335346,ISBN978-3-642-24455-1^abc"Reinforcement learning: An introduction"(PDF). Archived fromthe original(PDF)on 2017-07-12. Retrieved2017-07-23.^Singh, Satinder P.; Sutton, Richard S. (1996-03-01)."Reinforcement learning with replacing eligibility traces".Machine Learning.22(1): 123158.doi:10.1007/BF00114726.ISSN1573-0565.^Sutton, Richard S.(1984).Temporal Credit Assignment in Reinforcement Learning(PhD thesis). University of Massachusetts, Amherst, MA. Archived fromthe originalon 2017-03-30. Retrieved2017-03-29.^Sutton & Barto 2018,6. Temporal-Difference Learning.^Bradtke, Steven J.;Barto, Andrew G.(1996). "Learning to predict by the method of temporal differences".Machine Learning.22: 3357.CiteSeerX10.1.1.143.857.doi:10.1023/A:1018056104778.S2CID20327856.^Watkins, Christopher J.C.H.(1989).Learning from Delayed Rewards(PDF)(PhD thesis). Kings College, Cambridge, UK.^Matzliach, Barouch; Ben-Gal, Irad; Kagan, Evgeny (2022)."Detection of Static and Mobile Targets by an Autonomous Agent with Deep Q-Learning Abilities".Entropy.24(8):