and Robust Decision-Making: a CVaR Optimization Approach".Advances in Neural Information Processing Systems.28. Curran Associates, Inc.arXiv:1506.02188.^"Train Hard, Fight Easy: Robust Meta Reinforcement Learning".scholar.google.com. Retrieved2024-06-21.^Tamar, Aviv; Glassner, Yonatan; Mannor, Shie (2015-02-21)."Optimizing the CVaR via Sampling".Proceedings of the AAAI Conference on Artificial Intelligence.29(1).arXiv:1404.3862.doi:10.1609/aaai.v29i1.9561.ISSN2374-3468.^Greenberg, Ido; Chow, Yinlam; Ghavamzadeh, Mohammad; Mannor, Shie (2022-12-06)."Efficient Risk-Averse Reinforcement Learning".Advances in Neural Information Processing Systems.35: 3263932652.arXiv:2205.05138.^Bozinovski, S. (1982). "A self-learning system using secondary reinforcement". In Trappl, Robert (ed.). Cybernetics and Systems Research: Proceedings of the Sixth European Meeting on Cybernetics and Systems Research. North-Holland. pp. 397402. ISBN 978-0-444-86488-8^Bozinovski S. (1995) "Neuro genetic agents and structural theory of self-reinforcement learning systems". CMPSCI Technical Report 95-107, University of Massachusetts at Amherst[1]^Bozinovski, S. (2014) "Modeling mechanisms of cognition-emotion interaction in artificial neural networks, since 1981." Procedia Computer Science p. 255-263^Engstrom, Logan; Ilyas, Andrew; Santurkar, Shibani; Tsipras, Dimitris; Janoos, Firdaus; Rudolph, Larry; Madry, Aleksander (2019-09-25)."Implementation Matters in Deep RL: A Case Study on PPO and