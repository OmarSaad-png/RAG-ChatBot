3357.CiteSeerX10.1.1.143.857.doi:10.1023/A:1018056104778.S2CID20327856.^Watkins, Christopher J.C.H.(1989).Learning from Delayed Rewards(PDF)(PhD thesis). Kings College, Cambridge, UK.^Matzliach, Barouch; Ben-Gal, Irad; Kagan, Evgeny (2022)."Detection of Static and Mobile Targets by an Autonomous Agent with Deep Q-Learning Abilities".Entropy.24(8): 1168.Bibcode:2022Entrp..24.1168M.doi:10.3390/e24081168.PMC9407070.PMID36010832.^Williams, Ronald J.(1987). "A class of gradient-estimating algorithms for reinforcement learning in neural networks".Proceedings of the IEEE First International Conference on Neural Networks.CiteSeerX10.1.1.129.8871.^Peters, Jan;Vijayakumar, Sethu;Schaal, Stefan(2003).Reinforcement Learning for Humanoid Robotics(PDF). IEEE-RAS International Conference on Humanoid Robots. Archived fromthe original(PDF)on 2013-05-12.^Juliani, Arthur (2016-12-17)."Simple Reinforcement Learning with Tensorflow Part 8: Asynchronous Actor-Critic Agents (A3C)".Medium. Retrieved2018-02-22.^Deisenroth, Marc Peter;Neumann, Gerhard;Peters, Jan(2013).A Survey on Policy Search for Robotics(PDF). Foundations and Trends in Robotics. Vol. 2. NOW Publishers. pp. 1142.doi:10.1561/2300000021.hdl:10044/1/12051.^Sutton, Richard (1990). "Integrated Architectures for Learning, Planning and Reacting based on Dynamic Programming".Machine Learning: Proceedings of the Seventh International Workshop.^Lin, Long-Ji (1992)."Self-improving reactive agents based on reinforcement learning, planning and