8V.doi:10.1016/j.ijepes.2021.107628.S2CID244099841.^Sutton & Barto 2018, Chapter 11.^Ren, Yangang; Jiang, Jianhua; Zhan, Guojian; Li, Shengbo Eben; Chen, Chen; Li, Keqiang; Duan, Jingliang (2022)."Self-Learned Intelligence for Integrated Decision and Control of Automated Vehicles at Signalized Intersections".IEEE Transactions on Intelligent Transportation Systems.23(12): 2414524156.arXiv:2110.12359.doi:10.1109/TITS.2022.3196167.^Gosavi, Abhijit(2003).Simulation-based Optimization: Parametric Optimization Techniques and Reinforcement. Operations Research/Computer Science Interfaces Series. Springer.ISBN978-1-4020-7454-7.^abBurnetas, Apostolos N.;Katehakis, Michael N.(1997), "Optimal adaptive policies for Markov Decision Processes",Mathematics of Operations Research,22(1): 222255,doi:10.1287/moor.22.1.222,JSTOR3690147^Tokic, Michel; Palm, Gnther (2011),"Value-Difference Based Exploration: Adaptive Control Between Epsilon-Greedy and Softmax"(PDF),KI 2011: Advances in Artificial Intelligence, Lecture Notes in Computer Science, vol. 7006, Springer, pp. 335346,ISBN978-3-642-24455-1^abc"Reinforcement learning: An introduction"(PDF). Archived fromthe original(PDF)on 2017-07-12. Retrieved2017-07-23.^Singh, Satinder P.; Sutton, Richard S. (1996-03-01)."Reinforcement learning with replacing eligibility traces".Machine Learning.22(1): 123158.doi:10.1007/BF00114726.ISSN1573-0565.^Sutton, Richard S.(1984).Temporal Credit Assignment in Reinforcement Learning(PhD thesis). University of