Sethu;Schaal, Stefan(2003).Reinforcement Learning for Humanoid Robotics(PDF). IEEE-RAS International Conference on Humanoid Robots. Archived fromthe original(PDF)on 2013-05-12.^Juliani, Arthur (2016-12-17)."Simple Reinforcement Learning with Tensorflow Part 8: Asynchronous Actor-Critic Agents (A3C)".Medium. Retrieved2018-02-22.^Deisenroth, Marc Peter;Neumann, Gerhard;Peters, Jan(2013).A Survey on Policy Search for Robotics(PDF). Foundations and Trends in Robotics. Vol. 2. NOW Publishers. pp. 1142.doi:10.1561/2300000021.hdl:10044/1/12051.^Sutton, Richard (1990). "Integrated Architectures for Learning, Planning and Reacting based on Dynamic Programming".Machine Learning: Proceedings of the Seventh International Workshop.^Lin, Long-Ji (1992)."Self-improving reactive agents based on reinforcement learning, planning and teaching"(PDF).Machine Learning volume 8.doi:10.1007/BF00992699.^Zou, Lan (2023-01-01), Zou, Lan (ed.),"Chapter 7 - Meta-reinforcement learning",Meta-Learning, Academic Press, pp. 267297,doi:10.1016/b978-0-323-89931-4.00011-0,ISBN978-0-323-89931-4, retrieved2023-11-08^van Hasselt, Hado; Hessel, Matteo; Aslanides, John (2019)."When to use parametric models in reinforcement learning?"(PDF).Advances in Neural Information Processing Systems 32.^Grondman, Ivo; Vaandrager, Maarten; Busoniu, Lucian; Babuska, Robert; Schuitema, Erik (2012-06-01)."Efficient Model Learning Methods for ActorCritic Control".IEEE Transactions on Systems, Man, and Cybernetics, Part B