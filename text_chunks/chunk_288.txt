positive; if the current value of the state is 3 and the state transition attempts to reduce the value by 4, the transition will not be allowed. When the agent's performance is compared to that of an agent that acts optimally, the difference in performance yields the notion ofregret. In order to act near optimally, the agent must reason about long-term consequences of its actions (i.e., maximize future rewards), although the immediate reward associated with this might be negative. Thus, reinforcement learning is particularly well-suited to problems that include a long-term versus short-term reward trade-off. It has been applied successfully to various problems, includingenergy storage,[6]robot control,[7]photovoltaic generators,[8]backgammon,checkers,[9]Go(AlphaGo), andautonomous driving systems.[10] Two elements make reinforcement learning powerful: the use of samples to optimize performance, and the use offunction approximationto deal with large environments. Thanks to these two key components, RL can be used in large environments in the following situations: The first two