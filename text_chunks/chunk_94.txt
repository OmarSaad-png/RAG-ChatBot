while incremental methods are the only choice when batch methods are infeasible due to their high computational or memory complexity. Some methods try to combine the two approaches. Methods based on temporal differences also overcome the fourth issue.Another problem specific to TD comes from their reliance on the recursive Bellman equation. Most TD methods have a so-called{\displaystyle \lambda }parameter(01){\displaystyle (0\leq \lambda \leq 1)}that can continuously interpolate between Monte Carlo methods that do not rely on the Bellman equations and the basic TD methods that rely entirely on the Bellman equations. This can be effective in palliating this issue.Function approximation methods[edit]In order to address the fifth issue,function approximation methodsare used.Linear function approximationstarts with a mapping{\displaystyle \phi }that assigns a finite-dimensional vector to each state-action pair. Then, the action values of a state-action pair(s,a){\displaystyle (s,a)}are obtained by linearly combining the components of(s,a){\displaystyle \phi (s,a)}with someweights{\displaystyle \theta }:Q(s,a)=i=1dii(s,a).{\displaystyle Q(s,a)=\sum _{i=1}^{d}\theta _{i}\phi _{i}(s,a).}The algorithms then adjust the weights, instead of adjusting the values associated with the individual state-action pairs. Methods based on ideas fromnonparametric statistics(which can be seen to construct their own features) have been explored.Value iteration can also be used as a starting point,