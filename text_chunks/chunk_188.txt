a simulation model of the environment is given (the subject ofsimulation-based optimization);[11]The only way to collect information about the environment is to interact with it.The first two of these problems could be considered planning problems (since some form of model is available), while the last one could be considered to be a genuine learning problem. However, reinforcement learning converts both planning problems tomachine learningproblems.Exploration[edit]The exploration vs. exploitation trade-off has been most thoroughly studied through themulti-armed banditproblem and for finite state space Markov decision processes in Burnetas and Katehakis (1997).[12]Reinforcement learning requires clever exploration mechanisms; randomly selecting actions, without reference to an estimated probability distribution, shows poor performance. The case of (small) finite Markov decision processes is relatively well understood. However, due to the lack of algorithms that scale well with the number of states (or scale to problems with infinite state spaces), simple exploration m