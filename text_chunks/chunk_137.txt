e transition will not be allowed.When the agent's performance is compared to that of an agent that acts optimally, the difference in performance yields the notion ofregret. In order to act near optimally, the agent must reason about long-term consequences of its actions (i.e., maximize future rewards), although the immediate reward associated with this might be negative.Thus, reinforcement learning is particularly well-suited to problems that include a long-term versus short-term reward trade-off. It has been applied successfully to various problems, includingenergy storage,[6]robot control,[7]photovoltaic generators,[8]backgammon,checkers,[9]Go(AlphaGo), andautonomous driving systems.[10]Two elements make reinforcement learning powerful: the use of samples to optimize performance, and the use offunction approximationto deal with large environments. Thanks to these two key components, RL can be used in large environments in the following situations:A model of the environment is known, but ananalytic solutionis not available;Only a simulation model of the environment is given (the subject ofsimulation-based optimization);[11]The only way to collect information about the environment is to interact with it.The first two of these problems could be considered planning problems (since some form of model is available), while the last one could be considered to be a genuine learning problem. However, reinforcement learning converts both planning problems tomachine