Motivated Learning in Natural and Artificial Systems(PDF). Berlin; Heidelberg: Springer. pp. 1747.^Dabrius, Kevin; Granat, Elvin; Karlsson, Patrik (2020). "Deep Execution - Value and Policy Based Reinforcement Learning for Trading and Beating Market Benchmarks".The Journal of Machine Learning in Finance.1.SSRN3374766.^George Karimpanal, Thommen; Bouffanais, Roland (2019). "Self-organizing maps for storage and transfer of knowledge in reinforcement learning".Adaptive Behavior.27(2): 111126.arXiv:1811.08318.doi:10.1177/1059712318818568.ISSN1059-7123.S2CID53774629.^J Duan; Y Guan; S Li (2021)."Distributional Soft Actor-Critic: Off-policy reinforcement learning for addressing value estimation errors".IEEE Transactions on Neural Networks and Learning Systems.33(11): 65846598.arXiv:2001.02811.doi:10.1109/TNNLS.2021.3082568.PMID34101599.S2CID211259373.^Y Ren; J Duan; S Li (2020)."Improving Generalization of Reinforcement Learning with Minimax Distributional Soft Actor-Critic".2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC). pp. 16.arXiv:2002.05502.doi:10.1109/ITSC45102.2020.9294300.ISBN978-1-7281-4149-7.S2CID211096594.^Duan, J; Wang, W; Xiao, L (2023-10-26). "DSAC-T: Distributional Soft Actor-Critic with Three Refinements".arXiv:2310.05858[cs.LG].^Soucek, Branko (6 May 1992).Dynamic, Genetic and Chaotic Programming: The Sixth-Generation Computer Technology Series. John Wiley & Sons, Inc. p. 38.ISBN0-471-55717-X.^Francois-Lavet, Vincent; et al.