tools can be used for hypothesis testing, such asT-testandpermutation test.[68]This requires to accumulate all the rewards within an episode into a single number - the episodic return. However, this causes a loss of information, as different time-steps are averaged together, possibly with different levels of noise. Whenever the noise level varies across the episode, the statistical power can be improved significantly, by weighting the rewards according to their estimated noise.[69]See also[edit]Temporal difference learningQ-learningStateactionrewardstateaction(SARSA)Reinforcement learning from human feedbackOptimal controlError-driven learningMulti-agent reinforcement learningApprenticeship learningModel-free (reinforcement learning)active learning (machine learning)References[edit]^Kaelbling, Leslie P.;Littman, Michael L.;Moore, Andrew W.(1996)."Reinforcement Learning: A Survey".Journal of Artificial Intelligence Research.4: 237285.arXiv:cs/9605103.doi:10.1613/jair.301.S2CID1708582. Archived fromthe originalon 2001-11-20.^van Otterlo, M.; Wiering, M. (2012). "Reinforcement Learning and Markov Decision Processes".Reinforcement Learning. Adaptation, Learning, and Optimization. Vol. 12. pp. 342.doi:10.1007/978-3-642-27645-3_1.ISBN978-3-642-27644-6.^abLi, Shengbo (2023).Reinforcement Learning for Sequential Decision and Optimal Control(First ed.). Springer Verlag, Singapore. pp. 1460.doi:10.1007/978-981-19-7784-8.ISBN978-9-811-97783-1.S2CID257928563.{{cite book}}: CS1 maint: