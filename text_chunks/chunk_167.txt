"Human-level control through deep reinforcement learning".Nature.518(7540): 529533.Bibcode:2015Natur.518..529M.doi:10.1038/nature14236.PMID25719670.S2CID205242740.^Goodfellow, Ian; Shlens, Jonathan; Szegedy, Christian (2015). "Explaining and Harnessing Adversarial Examples".International Conference on Learning Representations.arXiv:1412.6572.^Behzadan, Vahid; Munir, Arslan (2017). "Vulnerability of Deep Reinforcement Learning to Policy Induction Attacks".Machine Learning and Data Mining in Pattern Recognition. Lecture Notes in Computer Science. Vol. 10358. pp. 262275.arXiv:1701.04143.doi:10.1007/978-3-319-62416-7_19.ISBN978-3-319-62415-0.S2CID1562290.^Pieter, Huang, Sandy Papernot, Nicolas Goodfellow, Ian Duan, Yan Abbeel (2017-02-07).Adversarial Attacks on Neural Network Policies.OCLC1106256905.{{cite book}}: CS1 maint: multiple names: authors list (link)^Korkmaz, Ezgi (2022)."Deep Reinforcement Learning Policies Learn Shared Adversarial Features Across MDPs".Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22).36(7): 72297238.arXiv:2112.09025.doi:10.1609/aaai.v36i7.20684.S2CID245219157.^Berenji, H.R. (1994)."Fuzzy Q-learning: A new approach for fuzzy dynamic programming".Proceedings of 1994 IEEE 3rd International Fuzzy Systems Conference. Orlando, FL, USA: IEEE. pp. 486491.doi:10.1109/FUZZY.1994.343737.ISBN0-7803-1896-X.S2CID56694947.^Vincze, David (2017)."Fuzzy rule interpolation and reinforcement learning"(PDF).2017 IEEE 15th International Symposium on